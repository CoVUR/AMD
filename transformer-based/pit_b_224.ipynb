{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import fastai\n",
    "import timm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../trainValid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nombre_foto</th>\n",
       "      <th>grado de DMAE</th>\n",
       "      <th>binary</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61504</td>\n",
       "      <td>anonymized_231059.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176989</td>\n",
       "      <td>anonymized_442122.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133399</td>\n",
       "      <td>anonymized_363034.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220150</td>\n",
       "      <td>anonymized_519072.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155853</td>\n",
       "      <td>anonymized_403989.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7797</th>\n",
       "      <td>224854</td>\n",
       "      <td>anonymized_528388.jpg</td>\n",
       "      <td>tardia</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>225492</td>\n",
       "      <td>anonymized_529721.jpg</td>\n",
       "      <td>intermedia</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7799</th>\n",
       "      <td>226322</td>\n",
       "      <td>anonymized_531350.jpg</td>\n",
       "      <td>precoz</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800</th>\n",
       "      <td>227489</td>\n",
       "      <td>anonymized_533460.jpg</td>\n",
       "      <td>tardia</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7801</th>\n",
       "      <td>227547</td>\n",
       "      <td>anonymized_533591.jpg</td>\n",
       "      <td>intermedia</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7802 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0            nombre_foto grado de DMAE  binary         set\n",
       "0          61504  anonymized_231059.jpg        normal       0    training\n",
       "1         176989  anonymized_442122.jpg        normal       0    training\n",
       "2         133399  anonymized_363034.jpg        normal       0    training\n",
       "3         220150  anonymized_519072.jpg        normal       0    training\n",
       "4         155853  anonymized_403989.jpg        normal       0    training\n",
       "...          ...                    ...           ...     ...         ...\n",
       "7797      224854  anonymized_528388.jpg        tardia       1  validation\n",
       "7798      225492  anonymized_529721.jpg    intermedia       1  validation\n",
       "7799      226322  anonymized_531350.jpg        precoz       1  validation\n",
       "7800      227489  anonymized_533460.jpg        tardia       1  validation\n",
       "7801      227547  anonymized_533591.jpg    intermedia       1  validation\n",
       "\n",
       "[7802 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(path):\n",
    "    name = path[1]\n",
    "    return (df[df['nombre_foto']==name])['set'].values[0]=='validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "callbacks = [\n",
    "    ShowGraphCallback(),\n",
    "    EarlyStoppingCallback(patience=5),\n",
    "    SaveModelCallback(fname='pit_b_224',monitor='f1_score'),\n",
    "    #ReduceLROnPlateau(patience=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 splitter=FuncSplitter(is_valid),\n",
    "                 get_x = ColReader(1,pref=\"../amd/\"),\n",
    "                 get_y=ColReader(3),\n",
    "                 item_tfms = [Resize(384)], # CropPad(200,200)\n",
    "                 batch_tfms=[*aug_transforms(size=224, min_scale=0.75,do_flip=True,flip_vert=True,\n",
    "                      max_rotate=2.,max_zoom=1.1, max_warp=0.05,p_affine=0.9, p_lighting=0.8), \n",
    "                             Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = db.dataloaders(df.values,bs=16,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls,timm.create_model('pit_b_224',num_classes=2,pretrained=True,drop_rate=0.5),\n",
    "                metrics=[accuracy,Precision(),Recall(),F1Score(),RocAucBinary()],\n",
    "                cbs=callbacks,\n",
    "                loss_func= FocalLossFlat()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(100,base_lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.virtualenvs/segmentation/lib/python3.6/site-packages/fastai/learner.py:56: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f4fd27e9390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('pit_b_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('../testSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_test(path):\n",
    "    name = path[1]\n",
    "    return (dfTest[dfTest['nombre_foto']==name])['set'].values[0]=='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbTest = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 splitter=FuncSplitter(is_test),\n",
    "                 get_x = ColReader(1,pref=\"../amd/\"),\n",
    "                 get_y=ColReader(3),\n",
    "                 item_tfms = [Resize(384)], # CropPad(200,200)\n",
    "                 batch_tfms=[*aug_transforms(size=224, min_scale=0.75,do_flip=True,flip_vert=True,\n",
    "                      max_rotate=2.,max_zoom=1.1, max_warp=0.05,p_affine=0.9, p_lighting=0.8), \n",
    "                             Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlsTest = dbTest.dataloaders(dfTest.values,bs=8,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls = dlsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with f1_score value: 0.7269401709401709.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#6) [0.1577601432800293,0.6410256624221802,0.5971731448763251,0.8666666666666667,0.7071129707112971,0.7269401709401709]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
